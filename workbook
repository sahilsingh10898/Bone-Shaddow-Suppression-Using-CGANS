{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":136367,"sourceType":"datasetVersion","datasetId":68239}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sssahilsingh/bone-shadow-suppression-using-cgans?scriptVersionId=193986492\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"e08db22b-6c3d-4485-9060-a8272580c5bf","_cell_guid":"721395aa-d09f-45e9-98ba-3ace0be027f7","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2024-08-24T17:42:13.79157Z","iopub.execute_input":"2024-08-24T17:42:13.792325Z","iopub.status.idle":"2024-08-24T17:42:18.413898Z","shell.execute_reply.started":"2024-08-24T17:42:13.79229Z","shell.execute_reply":"2024-08-24T17:42:18.412813Z"},"_kg_hide-output":true,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport os\nfrom keras.preprocessing.image import img_to_array ,load_img\nimport cv2 as cv\n\n\nimport tensorflow as tf \nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.initializers import RandomNormal\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module='tensorflow')\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","metadata":{"_uuid":"8bc84ee4-1843-4891-8ad5-3806ea7f3610","_cell_guid":"9f44421d-0ec6-4501-a404-26d948d64267","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:42:31.236471Z","iopub.execute_input":"2024-08-24T17:42:31.237516Z","iopub.status.idle":"2024-08-24T17:42:34.813351Z","shell.execute_reply.started":"2024-08-24T17:42:31.237482Z","shell.execute_reply":"2024-08-24T17:42:34.812326Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## preprocessing of the data","metadata":{"_uuid":"56e90f27-313c-4c40-9210-832831e66315","_cell_guid":"c178836c-ac40-4573-b239-1bd76a77a86a","trusted":true}},{"cell_type":"code","source":"path1='/kaggle/input/xray-bone-shadow-supression/augmented/augmented/target/0_0.png'\ntarget=cv.imread(path1)\nprint(target.shape)\nplt.imshow(target)","metadata":{"_uuid":"a1b03089-efe4-420b-95ab-0a0da0a70756","_cell_guid":"7c4c0932-4cbd-4114-a5be-90ac66dee9df","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:42:36.104005Z","iopub.execute_input":"2024-08-24T17:42:36.10513Z","iopub.status.idle":"2024-08-24T17:42:36.618117Z","shell.execute_reply.started":"2024-08-24T17:42:36.105093Z","shell.execute_reply":"2024-08-24T17:42:36.617098Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path2='/kaggle/input/xray-bone-shadow-supression/augmented/augmented/source/0_0.png'\ntarget1=cv.imread(path2)\nprint(target1.shape)\nplt.imshow(target1)","metadata":{"_uuid":"9687a380-2814-4ae7-af81-fd624714cbfc","_cell_guid":"85c64c86-620c-4361-8690-4f5a88092443","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:42:39.440512Z","iopub.execute_input":"2024-08-24T17:42:39.441462Z","iopub.status.idle":"2024-08-24T17:42:39.944517Z","shell.execute_reply.started":"2024-08-24T17:42:39.441419Z","shell.execute_reply":"2024-08-24T17:42:39.943556Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset(path):\n    path_list=[]\n    for file in os.listdir(path):\n        if file.endswith('.png'):\n            img_path=os.path.join(path,file)\n            path_list.append(img_path)\n            \n    return path_list","metadata":{"_uuid":"4c52997b-57ba-4977-8e8c-02c3f5b8e64b","_cell_guid":"e024a35d-b525-4748-803e-f307d36ae9b7","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:42:42.874431Z","iopub.execute_input":"2024-08-24T17:42:42.87506Z","iopub.status.idle":"2024-08-24T17:42:42.880456Z","shell.execute_reply.started":"2024-08-24T17:42:42.875015Z","shell.execute_reply":"2024-08-24T17:42:42.879409Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"src='/kaggle/input/xray-bone-shadow-supression/augmented/augmented/source'\ntar='/kaggle/input/xray-bone-shadow-supression/augmented/augmented/target'","metadata":{"_uuid":"69563793-befe-490a-a81d-dddf288b904b","_cell_guid":"f20d5cdb-2fda-498f-b230-4bf095a17925","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:42:45.107824Z","iopub.execute_input":"2024-08-24T17:42:45.108565Z","iopub.status.idle":"2024-08-24T17:42:45.112849Z","shell.execute_reply.started":"2024-08-24T17:42:45.108529Z","shell.execute_reply":"2024-08-24T17:42:45.111881Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_pathlist=dataset(src)\ntarget_pathlist=dataset(tar)\nprint(f\"source sample length :- {len(source_pathlist)}, target sample length :- {len(target_pathlist)}\")","metadata":{"_uuid":"bbee6a14-9f80-4eda-beaf-45242cf323d4","_cell_guid":"077cb2ed-e14f-42d5-971d-b5d800240a8a","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:42:48.095579Z","iopub.execute_input":"2024-08-24T17:42:48.096221Z","iopub.status.idle":"2024-08-24T17:42:48.12494Z","shell.execute_reply.started":"2024-08-24T17:42:48.09619Z","shell.execute_reply":"2024-08-24T17:42:48.123908Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image='/kaggle/input/xray-bone-shadow-supression/augmented/augmented/target/0_0.png'\ndef check(path):\n    i=tf.io.read_file(image)\n    i=tf.image.decode_image(i,channels=3)\n    i=tf.image.resize(i,(512,512),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    i=tf.cast(i,tf.float32)/255\n    i=(i-0.5)*2\n    #i4=tf.cast()\n    print(i.shape)\n    i=(i+1)/2.0\n\n\n    plt.imshow(i)","metadata":{"_uuid":"2e7f4517-8d2d-4691-b7c4-a2588de71428","_cell_guid":"39aa2761-1ae4-427b-8236-e84210a87ca3","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:42:50.902662Z","iopub.execute_input":"2024-08-24T17:42:50.903598Z","iopub.status.idle":"2024-08-24T17:42:50.910592Z","shell.execute_reply.started":"2024-08-24T17:42:50.903557Z","shell.execute_reply":"2024-08-24T17:42:50.909518Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check(image)","metadata":{"_uuid":"b5ec03b7-dd9d-4c1b-a273-9542cb5a5603","_cell_guid":"47d5b4a3-f464-4fb0-adca-10a6d8b14c9b","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:42:53.73279Z","iopub.execute_input":"2024-08-24T17:42:53.733467Z","iopub.status.idle":"2024-08-24T17:42:54.600824Z","shell.execute_reply.started":"2024-08-24T17:42:53.733433Z","shell.execute_reply":"2024-08-24T17:42:54.599774Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using tensorflow dataset api to create data pipeline","metadata":{"_uuid":"6cc25a05-cf32-4a8e-add8-da7aa163b9b7","_cell_guid":"a9366355-c3cf-49db-b9e8-573f6ce5b328","trusted":true}},{"cell_type":"code","source":"def preprocessing(source_path_list,target_path_list,shape):\n    'tf.io.read_file:- takes source'\n    src_img=tf.io.read_file(source_path_list)\n    src_img=tf.image.decode_image(src_img,channels=3)\n    \n    'set the shape of image to -> (sahpe,shape,3)'\n    \n    src_img.set_shape([None,None,3])\n    \n    'Resize the image'\n    \n    src_img=tf.image.resize(src_img,(shape,shape),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    src_img=tf.cast(src_img,tf.float32)/255\n    \n    'Normalize the image to [-1,1]'\n    \n    src_img=(src_img-0.5)*2\n    \n    ## For target image\n    tar_img=tf.io.read_file(target_path_list)\n    tar_img=tf.image.decode_image(tar_img,channels=3)\n    \n    'set the shape of image to -> (sahpe,shape,3)'\n    \n    tar_img.set_shape([None,None,3])\n    \n    'Resize the image'\n    \n    tar_img=tf.image.resize(tar_img,(shape,shape),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    tar_img=tf.cast(tar_img,tf.float32)/255\n    \n    'Normalize the image to [-1,1]'\n    \n    tar_img=(tar_img-0.5)*2\n    \n    return src_img,tar_img","metadata":{"_uuid":"77eba231-40cf-4cbc-8d8b-782b443a2741","_cell_guid":"1b9f76dc-bbdd-4935-b36a-b7e6617c0ea4","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:42:57.700934Z","iopub.execute_input":"2024-08-24T17:42:57.701404Z","iopub.status.idle":"2024-08-24T17:42:57.710679Z","shell.execute_reply.started":"2024-08-24T17:42:57.701372Z","shell.execute_reply":"2024-08-24T17:42:57.709575Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"src_img,tar_img=preprocessing(path2,path1,512)\nsrc_img=(src_img+1)/2\nplt.imshow(src_img)","metadata":{"_uuid":"1efde6f6-c9b2-4f0b-b256-b93eb1fbd6d3","_cell_guid":"901c9520-a61b-4597-9ebe-f57e52e83b55","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:43:01.381244Z","iopub.execute_input":"2024-08-24T17:43:01.382007Z","iopub.status.idle":"2024-08-24T17:43:01.798057Z","shell.execute_reply.started":"2024-08-24T17:43:01.381976Z","shell.execute_reply":"2024-08-24T17:43:01.797096Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset(source_pathlist,target_pathlist,shape,test_size=0.2,batch_size=16,shuffle=True):\n    dataset=tf.data.Dataset.from_tensor_slices((source_pathlist,target_pathlist))\n    \n    if shuffle:\n        dataset=dataset.shuffle(buffer_size=len(source_pathlist))\n        \n    # apply the preprocessing function to the dataset\n    \n    dataset=dataset.map(lambda src_image,tar_image : preprocessing(src_image,tar_image,shape),\n                       num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    \n    # implement test train split\n    \n    dataset_size=len(source_pathlist)\n    test_size=int(test_size*dataset_size)\n    train_size=dataset_size-test_size\n    \n    train_dataset=dataset.take(train_size)\n    test_dataset=dataset.skip(test_size)\n    \n    # making the dataset in batches\n    \n    train_dataset=train_dataset.batch(batch_size)\n    test_dataset=test_dataset.batch(batch_size)\n    \n    # prefetch the data for better performance\n    \n    train_dataset=train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n    test_dataset=test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n    \n    return train_dataset,test_dataset","metadata":{"_uuid":"8f1071ac-5d67-42ca-8478-295f81505b30","_cell_guid":"ebe1f23f-e95b-42ac-9e18-1d56c4b83e02","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:43:09.093477Z","iopub.execute_input":"2024-08-24T17:43:09.094293Z","iopub.status.idle":"2024-08-24T17:43:09.10234Z","shell.execute_reply.started":"2024-08-24T17:43:09.09425Z","shell.execute_reply":"2024-08-24T17:43:09.101372Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset,test_dataset=create_dataset(source_pathlist,target_pathlist,batch_size=16,shape=256)","metadata":{"_uuid":"87e10a00-96d3-4b8f-91e1-3a10a9deeb00","_cell_guid":"02fc2bda-34a9-4ee7-a8f5-d4204e9a80e7","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:43:12.165851Z","iopub.execute_input":"2024-08-24T17:43:12.166243Z","iopub.status.idle":"2024-08-24T17:43:12.404424Z","shell.execute_reply.started":"2024-08-24T17:43:12.166213Z","shell.execute_reply":"2024-08-24T17:43:12.403523Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef show_samples_from_dataset(dataset, num_batches=1):\n    # Iterate through the dataset\n    for batch_num, (src_img, tar_img) in enumerate(dataset.take(num_batches)):\n        # Rescale the images from [-1, 1] to [0, 1] for display\n        src_img = (src_img + 1) / 2.0\n        tar_img = (tar_img + 1) / 2.0\n\n        # Plot the images\n        plt.figure(figsize=(20,20))\n        for i in range(len(src_img)):\n            plt.subplot(len(src_img), 2, i * 2 + 1)\n            plt.imshow(src_img[i])\n            plt.title(\"Source Image\")\n            plt.axis(\"off\")\n\n            plt.subplot(len(src_img), 2, i * 2 + 2)\n            plt.imshow(tar_img[i])\n            plt.title(\"Target Image\")\n            plt.axis(\"off\")\n        \n        plt.show()\n\n# Example usage: Show images from one batch of the train_dataset\nshow_samples_from_dataset(train_dataset, num_batches=1)","metadata":{"_uuid":"12cbcac4-ecd3-49e8-9507-a809fe93f1f6","_cell_guid":"bc066baf-4103-4778-a591-cd8325d76df5","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:43:36.772118Z","iopub.execute_input":"2024-08-24T17:43:36.773023Z","iopub.status.idle":"2024-08-24T17:43:39.542454Z","shell.execute_reply.started":"2024-08-24T17:43:36.772992Z","shell.execute_reply":"2024-08-24T17:43:39.541476Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"src_image,tar_image=next(iter(train_dataset))\nprint(f\"src_image shape :-> {src_image.shape}  tar_image shape :-> {tar_image.shape}\")","metadata":{"_uuid":"0be9357c-8663-4218-8a7c-dfd4df67f80a","_cell_guid":"4c8c4d1e-5483-466c-8397-48933a40ff48","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:43:45.390562Z","iopub.execute_input":"2024-08-24T17:43:45.390994Z","iopub.status.idle":"2024-08-24T17:43:45.768035Z","shell.execute_reply.started":"2024-08-24T17:43:45.390962Z","shell.execute_reply":"2024-08-24T17:43:45.76699Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## making discriminator model for the cgan architecture\ndef descriminator():\n    input_img_source=Input(shape=(size,size,3))\n    input_img_target=Input(shape=(size,size,3))\n    \n    init=RandomNormal(stddev=0.02)\n    \n    merged=Concatenate()([input_img_source,input_img_target])\n    \n    x=Conv2D(64,(4,4),strides=(2,2),padding='same',kernel_initializer=init)(merged)\n    x=LeakyReLU(alpha=0.2)(x)\n    \n    x=Conv2D(128,(4,4),strides=(2,2),padding='same',kernel_initializer=init)(x)\n    x=BatchNormalization()(x)\n    x=LeakyReLU(alpha=0.2)(x)\n    \n    x=Conv2D(256,(4,4),strides=(2,2),padding='same',kernel_initializer=init)(x)\n    x=BatchNormalization()(x)\n    x=LeakyReLU(alpha=0.2)(x)\n    \n    \n    x=Conv2D(512,(4,4),strides=(2,2),padding='same',kernel_initializer=init)(x)\n    x=BatchNormalization()(x)\n    x=LeakyReLU(alpha=0.2)(x)\n    \n     ## second output layer\n    x=Conv2D(512,(4,4),strides=(1,1),padding='same',kernel_initializer=init)(x)\n    x=BatchNormalization()(x)\n    x=LeakyReLU(alpha=0.2)(x)\n    \n    #output layer\n    \n    output=Conv2D(1,(4,4),padding='same',kernel_initializer=init,activation='sigmoid')(x)\n    \n    model=Model([input_img_source,input_img_target],output)\n    \n    opt=Adam(learning_rate=0.0002,beta_1=0.5)\n    \n    model.compile(loss='binary_crossentropy',optimizer=opt,loss_weights=[0.5])\n    \n    return model","metadata":{"_uuid":"0bbd739a-cb2c-4a17-a9fb-9eb4af2aa3b1","_cell_guid":"69490114-281a-4c6d-bbbf-26e9cdcaa362","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:43:49.757068Z","iopub.execute_input":"2024-08-24T17:43:49.757981Z","iopub.status.idle":"2024-08-24T17:43:49.769624Z","shell.execute_reply.started":"2024-08-24T17:43:49.757947Z","shell.execute_reply":"2024-08-24T17:43:49.76853Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"size=256\nd_model=descriminator()\nd_model.summary()","metadata":{"_uuid":"3796b7a4-aa33-41ac-9871-60e1e15083e0","_cell_guid":"00fab244-5ecf-4a0e-beba-9fef7dfbd89a","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T17:43:53.1703Z","iopub.execute_input":"2024-08-24T17:43:53.17068Z","iopub.status.idle":"2024-08-24T17:43:53.325317Z","shell.execute_reply.started":"2024-08-24T17:43:53.170651Z","shell.execute_reply":"2024-08-24T17:43:53.324437Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Generator Architecture\ndef encoder(layer_in,n_filters,batchnorm=True):\n    init=RandomNormal(stddev=0.02)\n    ## adding downsampling layer\n    \n    x=Conv2D(n_filters,(4,4),strides=(2,2),padding='same',kernel_initializer=init)(layer_in)\n    ## conditionally add batchnormalization\n    if batchnorm:\n        x=BatchNormalization()(x,training=True)\n        \n    x=LeakyReLU(alpha=0.2)(x)\n    \n    return x\n\n\ndef decoder(layer_in,skip,n_filters,dropout=True):\n    \n    init=RandomNormal(stddev=0.02)\n    \n    # adding upsampling layer\n    \n    x=Conv2DTranspose(n_filters,(4,4),strides=(2,2),padding='same',kernel_initializer=init)(layer_in)\n    x=BatchNormalization()(x)\n    \n    # add conditional dropout layer\n    if dropout:\n        x=Dropout(0.5)(x)\n        \n    # merge with skip connection\n    x=Concatenate()([x,skip])\n    x=LeakyReLU(alpha=0.2)(x)\n    \n    return x","metadata":{"_uuid":"fe79d59f-c576-49d2-ba96-033f60c9b04d","_cell_guid":"02c56b17-de42-4911-b1e2-929307f7aae8","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T18:12:57.457112Z","iopub.execute_input":"2024-08-24T18:12:57.457855Z","iopub.status.idle":"2024-08-24T18:12:57.466101Z","shell.execute_reply.started":"2024-08-24T18:12:57.457818Z","shell.execute_reply":"2024-08-24T18:12:57.465189Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator():\n    init=RandomNormal(stddev=0.02)\n    input_layer_source=Input(shape=(size,size,3))\n    \n    \n    \n    # DownSampling layer\n    \n    \n    e1=encoder(input_layer_source,64,batchnorm=False)\n    e2=encoder(e1,128)\n    e3=encoder(e2,256)\n    e4=encoder(e3,512)\n    e5=encoder(e4,512)\n    e6=encoder(e5,512)\n    e7=encoder(e6,512)\n    \n    \n    ## simple bridge layer\n    \n    x=Conv2D(512,(4,4),strides=(2,2),kernel_initializer=init,padding='same',activation='relu')(e7)\n    \n    ## Upsampling Layer\n    \n    u1=decoder(x,e7,512)\n    u2=decoder(u1,e6,512)\n    u3=decoder(u2,e5,512)\n    u4=decoder(u3,e4,512,dropout=False)\n    u5=decoder(u4,e3,256,dropout=False)\n    u6=decoder(u5,e2,128,dropout=False)\n    u7=decoder(u6,e1,64,dropout=False)\n    \n    u8=UpSampling2D(size=(2,2))(u7)\n    \n    ## output layer\n    \n    output=Conv2D(3,(4,4),strides=(1,1),padding='same',kernel_initializer=init,activation='tanh')(u8)\n    \n    model=Model(input_layer_source,output)\n    return model","metadata":{"_uuid":"56595702-bc47-48f6-bfc0-78cc1760d377","_cell_guid":"e1e9af80-5ab4-4f2f-96bf-60ae0dbb7ad0","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T18:17:01.685838Z","iopub.execute_input":"2024-08-24T18:17:01.686516Z","iopub.status.idle":"2024-08-24T18:17:01.696675Z","shell.execute_reply.started":"2024-08-24T18:17:01.686482Z","shell.execute_reply":"2024-08-24T18:17:01.695712Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g_model=generator()\ng_model.summary()","metadata":{"_uuid":"94027114-32a8-4576-aa1e-5ccef0c67d22","_cell_guid":"f703f9aa-d7f7-436d-a9de-2c53a6df419f","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T18:17:04.339864Z","iopub.execute_input":"2024-08-24T18:17:04.340241Z","iopub.status.idle":"2024-08-24T18:17:04.66602Z","shell.execute_reply.started":"2024-08-24T18:17:04.34021Z","shell.execute_reply":"2024-08-24T18:17:04.66518Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## important question is what is going to be mine loss function\n# what should be loss function of the discriminator and what should be my loss function for the generator\n## using the ssim loss for the gan model","metadata":{"_uuid":"63f3e5fe-e38f-4b7a-9493-87af547be215","_cell_guid":"2646283f-2c40-4e3e-bd40-4e0955669a5e","execution":{"iopub.status.busy":"2024-07-27T16:51:38.826016Z","iopub.execute_input":"2024-07-27T16:51:38.826418Z","iopub.status.idle":"2024-07-27T16:51:38.834395Z","shell.execute_reply.started":"2024-07-27T16:51:38.826386Z","shell.execute_reply":"2024-07-27T16:51:38.83331Z"},"trusted":true}},{"cell_type":"markdown","source":"Q:- why am using the ssim as a loss function\n\n1- ssim will force the generator to produce the images that represents close structural similarity\n\n2- L1 loss only depends upon the pixel values between actual image and generated image\n   whereas this ssim loss depends upon three parameters","metadata":{"_uuid":"a61782b2-3b10-475c-b461-5305ad885d18","_cell_guid":"e33af9f1-6cfc-458e-8f5b-c513113cbecb","trusted":true}},{"cell_type":"code","source":"loss=BinaryCrossentropy(from_logits=False)\nopt_dis=Adam(0.001,beta_1=0.9,beta_2=0.999)\nopt_gen=Adam(0.001,beta_1=0.9,beta_2=0.999)\n\nweight_1=100.0\nweight_2=0.5\n\n\n\n\ndef generator_loss(dis_gen_output,gen_output,target):\n    'dis_gen_output:- discriminator generated output'\n    \n    gen_loss=loss(tf.ones_like(dis_gen_output),dis_gen_output)\n    \n    ## use l2 loss and ssim loss as combined loss function for training\n    l1_loss=tf.reduce_mean(tf.abs(target-gen_output))\n    \n    ssim_loss=1-tf.reduce_mean(tf.image.ssim(gen_output,target,max_val=1.0))\n    psnr_value=tf.image.psnr(gen_output,target,max_val=1.0)\n    mean_psnr = tf.reduce_mean(psnr_value)\n    \n    total_gen_loss=gen_loss + weight_1*l1_loss + weight_2*ssim_loss\n    \n    return total_gen_loss,gen_loss,l1_loss,ssim_loss,mean_psnr\n\n\ndef discriminator_loss(dis_real_output,dis_gen_output):\n    real_loss=loss(tf.ones_like(dis_real_output),dis_real_output)\n    gen_loss=loss(tf.zeros_like(dis_gen_output),dis_gen_output)\n    \n    total_loss=real_loss + gen_loss\n    \n    return total_loss","metadata":{"_uuid":"bb9555ea-5b74-41d6-916d-3fb5753d8597","_cell_guid":"9c6dff41-17f6-43bb-a953-140bef454d60","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T18:42:59.428484Z","iopub.execute_input":"2024-08-24T18:42:59.429165Z","iopub.status.idle":"2024-08-24T18:42:59.442798Z","shell.execute_reply.started":"2024-08-24T18:42:59.429114Z","shell.execute_reply":"2024-08-24T18:42:59.441805Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training(input_image,target,epochs):\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n        gen_output=g_model(input_image,training=True)\n        \n        dis_real_output=d_model([input_image,target],training=True)\n        dis_gen_output=d_model([input_image,gen_output],training=True)\n        \n        total_gen_loss,gen_loss,l1_loss,ssim_loss,mean_psnr=generator_loss(dis_gen_output,gen_output,target)       \n        dis_loss=discriminator_loss(dis_real_output,dis_gen_output)\n        \n        gen_gradients=gen_tape.gradient(total_gen_loss,g_model.trainable_variables)\n        dis_gradients=dis_tape.gradient(dis_loss,d_model.trainable_variables)\n        \n        opt_gen.apply_gradients(zip(gen_gradients,g_model.trainable_variables))\n        opt_dis.apply_gradients(zip(dis_gradients,d_model.trainable_variables))\n        \n        return total_gen_loss,gen_loss,ssim_loss,mean_psnr,dis_loss","metadata":{"_uuid":"7aa37de6-f25e-4f2e-9d1c-a5a5e859a5ed","_cell_guid":"c84901dd-2504-4059-b343-70b507615b04","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T18:43:02.641212Z","iopub.execute_input":"2024-08-24T18:43:02.642197Z","iopub.status.idle":"2024-08-24T18:43:02.650689Z","shell.execute_reply.started":"2024-08-24T18:43:02.642159Z","shell.execute_reply":"2024-08-24T18:43:02.649452Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(training_dataset,epochs):\n    for epoch in range(epochs):\n        print(f\"Epoch :- {epoch+1}/{epochs}\")\n        \n        for n,(src_img,tar_img) in training_dataset.enumerate():\n            \n            total_gen_loss,gen_loss,ssim_loss,mean_psnr,dis_loss=training(src_img,tar_img,epochs)\n            \n            \n            if n % 100==0:\n                print(f\"step :- {n}\")\n                print(f\"  Generator Total Loss: {total_gen_loss.numpy():.4f}\")\n                print(f\"  Generator GAN Loss: {gen_loss.numpy():.4f}\")\n                print(f\"  Discriminator Loss: {dis_loss.numpy():.4f}\")\n                print(f\"  SSIM Loss: {ssim_loss.numpy():.4f}\")\n                print(f\" PSNR Value: {mean_psnr.numpy():.4f}\")\n                \n    g_model.save('/kaggle/working/g_model.h5')\n    d_model.save('/kaggle/working/d_model.h5')","metadata":{"_uuid":"f650eb3b-4786-415e-9e98-39af32a1a49a","_cell_guid":"909c5636-55da-4bcf-82dd-740b3a153226","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T18:43:04.987063Z","iopub.execute_input":"2024-08-24T18:43:04.987995Z","iopub.status.idle":"2024-08-24T18:43:04.995285Z","shell.execute_reply.started":"2024-08-24T18:43:04.987946Z","shell.execute_reply":"2024-08-24T18:43:04.99422Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit(train_dataset,epochs=60)","metadata":{"_uuid":"5fff2f95-8cb8-450f-b0c9-a61c62d80015","_cell_guid":"81e629fb-d73c-47e5-8379-0a03ae22fc85","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T18:43:07.801744Z","iopub.execute_input":"2024-08-24T18:43:07.802101Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef predict_and_plot_images(model, dataset, num_batches=1):\n    # Loop through the dataset and make predictions\n    for batch_num, (src_img, tar_img) in enumerate(dataset.take(num_batches)):\n        # Predict the output from the model\n        pred_img = model.predict(src_img)\n\n        # Rescale the images from [-1, 1] to [0, 1] for plotting\n        src_img = (src_img + 1) / 2.0\n        tar_img = (tar_img + 1) / 2.0\n        pred_img = (pred_img + 1) / 2.0\n\n        # Plot the images\n        plt.figure(figsize=(20, 20))\n        for i in range(len(src_img)):\n            plt.subplot(len(src_img), 3, i * 3 + 1)\n            plt.imshow(src_img[i])\n            plt.title(\"Input Image\")\n            plt.axis(\"off\")\n\n            plt.subplot(len(src_img), 3, i * 3 + 2)\n            plt.imshow(tar_img[i])\n            plt.title(\"Target Image\")\n            plt.axis(\"off\")\n\n            plt.subplot(len(src_img), 3, i * 3 + 3)\n            plt.imshow(pred_img[i])\n            plt.title(\"Predicted Image\")\n            plt.axis(\"off\")\n\n        plt.show()\n\n# Example usage with the test dataset\npredict_and_plot_images(g_model, test_dataset, num_batches=1)","metadata":{"_uuid":"84b12e8e-8f61-485f-9872-f6978a9782f4","_cell_guid":"1627da72-5e6b-4c4c-bb3e-3a2af8fa8239","collapsed":false,"execution":{"iopub.status.busy":"2024-08-24T18:30:23.865001Z","iopub.execute_input":"2024-08-24T18:30:23.865901Z","iopub.status.idle":"2024-08-24T18:30:40.502199Z","shell.execute_reply.started":"2024-08-24T18:30:23.865864Z","shell.execute_reply":"2024-08-24T18:30:40.501233Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"a10a7948-53f9-44d2-ae9f-61fa153080ab","_cell_guid":"ae9c0e78-71a3-4fbd-be08-414deddbdd9d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"94dbaa75-0164-4117-a9fe-d332892f404c","_cell_guid":"fefeda9f-fb7f-417e-add3-c4c7d142e828","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}